{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import pafy\n",
    "import random\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "from moviepy.editor import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definições Globais\n",
    "\n",
    "seed_constant = 23\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)\n",
    "\n",
    "# Diretórios raiz dos datasets\n",
    "dataset_dir = '../../dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9169a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1 & 2 [Download e Visualizar o Dataset]\n",
    "# Descarregar e descomprimir o dataset para a pasta \"datasets\" \n",
    "\n",
    "# Obter nomes das classes através dos nomes das pastas\n",
    "all_classes_names = os.listdir(dataset_dir + 'UCF50')\n",
    "\n",
    "# Criar figura Matplotlib\n",
    "plt.figure(figsize = (30, 30))\n",
    "\n",
    "# Gerar conjunto aleatório de imagens sempre que a célula correr\n",
    "random_range = random.sample(range(len(all_classes_names)), 20)\n",
    "\n",
    "# Iterar todos os elementos do conjunto aleatório\n",
    "for counter, random_index in enumerate(random_range, 1):\n",
    "\n",
    "    # Obter nome da classe\n",
    "    selected_class_Name = all_classes_names[random_index]\n",
    "    \n",
    "    # Obter lista de ficheiros video presentes na pasta da classe\n",
    "    video_files_names_list = os.listdir(dataset_dir + f'UCF50/{selected_class_Name}')\n",
    "\n",
    "    # Selecionar video aleatório\n",
    "    selected_video_file_name = random.choice(video_files_names_list)\n",
    "    \n",
    "    # Ler ficheiro de vídeo usando o VideoCapture\n",
    "    video_reader = cv2.VideoCapture(dataset_dir + f'UCF50/{selected_class_Name}/{selected_video_file_name}')\n",
    "\n",
    "    # Ler primeira Frame do ficheiro de vídeo\n",
    "    _, bgr_frame = video_reader.read()\n",
    "\n",
    "    # Fechar o objecto VideoCapture para libertar recursos\n",
    "    video_reader.release()\n",
    "\n",
    "    # Converter a Frame do vídeo de BGR para RGB\n",
    "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Adicionar o nome da classe ao topo da Frame de vídeo\n",
    "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Associar a Frame a uma posição específica do subplot\n",
    "    plt.subplot(5, 4, counter)\n",
    "    plt.imshow(rgb_frame)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce003633",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3 [Ler e Pré-processar Dataset]\n",
    "\n",
    "image_height, image_width = 64, 64\n",
    "max_images_per_class = 8000\n",
    "dataset_name = \"UCF50\"\n",
    "classes_list = [\"WalkingWithDog\", \"TaiChi\", \"Swing\", \"HorseRace\"]\n",
    "model_output_size = len(classes_list)\n",
    "\n",
    "def frames_extraction(video_path):\n",
    "    \n",
    "    frames_list = []\n",
    "    \n",
    "    # Ler ficheiro de vídeo usando o VideoCapture\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Iterar as frames do vídeo\n",
    "    while True:\n",
    "        # Ler frame do ficheiro de vídeo\n",
    "        success, frame = video_reader.read()\n",
    "        \n",
    "        # Se não ler frame de vídeo com sucesso, quebra o loop\n",
    "        if not success:\n",
    "            break\n",
    "            \n",
    "        # Redimensionar frame para as dimensões especificadas\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        \n",
    "        # Normalizar a frame, dividindo por 255, para que cada valor de pixel seja entre 0 e 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Adicionar a frame normalizada à lista de frames\n",
    "        frames_list.append(normalized_frame)\n",
    "        \n",
    "    # Fechar o objecto VideoCapture para libertar recursos\n",
    "    video_reader.release()\n",
    "\n",
    "    return frames_list\n",
    "\n",
    "def create_dataset():\n",
    "    \n",
    "    temp_features = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterar todas as classes\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "\n",
    "        # Obter lista de ficheiros video presentes na pasta da classe\n",
    "        files_list = os.listdir(os.path.join(dataset_dir + dataset_name, class_name))\n",
    "\n",
    "        # Iterar todos os ficheiros presentes na lista\n",
    "        for file_name in files_list:\n",
    "\n",
    "            # Preparar o caminho do ficheiro\n",
    "            video_file_path = os.path.join(dataset_dir + dataset_name, class_name, file_name)\n",
    "\n",
    "            # Extrair as frames do ficheiro vídeo\n",
    "            frames = frames_extraction(video_file_path)\n",
    "\n",
    "            # Adicionar as frames a uma lista temporária\n",
    "            temp_features.extend(frames)\n",
    "            \n",
    "        # Adicionar frames aleatórias à lista das features\n",
    "        features.extend(random.sample(temp_features, max_images_per_class))\n",
    "        \n",
    "        # Adicionar números fixos das labels à lista das labels\n",
    "        labels.extend([class_index] * max_images_per_class)\n",
    "        \n",
    "        # Esvaziar lista temporária para que possa ser reutilizada\n",
    "        temp_features.clear()\n",
    "        \n",
    "    # Converter listas de features e labels em arrays numpy\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels) \n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6beecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar dataset\n",
    "features, labels = create_dataset()\n",
    "\n",
    "# Converter labels para formato one_hot_encoded\n",
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4 [Dividir dataset em Sets de treino e test]\n",
    "\n",
    "# Split de Treino e Teste de 80% e 20%\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.2, shuffle = True, random_state = seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5 [Construir Modelo]\n",
    "\n",
    "def create_model():\n",
    "    # Vai-se utilizar um modelo sequencial\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Definir a arquitetura do modelo\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(model_output_size, activation = 'softmax'))\n",
    "    \n",
    "    # Imprimir sumário do modelo\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# Criar modelo\n",
    "model = create_model()\n",
    "\n",
    "print(\"Model Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f6fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar estrutura do modelo\n",
    "plot_model(model, to_file = 'model_structure_plot.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6 [Compilar e Treinar o Modelo]\n",
    "\n",
    "# Adicionar Callback para Early Stopping\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "# Adicionar perda, optimizador e valores de métricas ao modelo\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "# Iniciar Treino\n",
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "model_training_history = model.fit(x = features_train, y = labels_train, epochs = epochs, batch_size = batch_size , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a53dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar Modelo\n",
    "model_evaluation_history = model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar nome útil para o modelo no caso de haver múltiplos modelos\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "model_name = f'Model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "# Gravar Modelo\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66704d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7 [Plot das curvas de perda e precisão]\n",
    "\n",
    "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
    "    # Obter valores das métricas usando nomes como identificadores\n",
    "    metric_value_1 = model_training_history.history[metric_name_1]\n",
    "    metric_value_2 = model_training_history.history[metric_name_2]\n",
    "    \n",
    "    # Criar objecto range que servirá de tempo\n",
    "    epochs = range(len(metric_value_1))\n",
    "    \n",
    "    # Plotar o gráfico\n",
    "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "\n",
    "    # Adicionar título ao plot\n",
    "    plt.title(str(plot_name))\n",
    "    \n",
    "    # Adicionar legenda ao plot\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63354530",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28938296",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2833c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 8 [Fazer Previsões usando o modelo]\n",
    "\n",
    "def download_youtube_videos(youtube_video_url, output_directory):\n",
    "    # Creating a Video object which includes useful information regarding the youtube video.\n",
    "    video = pafy.new(youtube_video_url)\n",
    "\n",
    "    # Getting the best available quality object for the youtube video.\n",
    "    video_best = video.getbest()\n",
    "\n",
    "    # Constructing the Output File Path\n",
    "    output_file_path = f'{output_directory}/{video.title}.mp4'\n",
    "    \n",
    "    # Downloading the youtube video at the best available quality.\n",
    "    video_best.download(filepath = output_file_path, quiet = True)\n",
    "\n",
    "    # Returning Video Title\n",
    "    return video.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_live_video(video_file_path, output_file_path, window_size):\n",
    "    # Initialize a Deque Object with a fixed size which will be used to implement moving/rolling average functionality.\n",
    "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    "\n",
    "    # Reading the Video File using the VideoCapture Object\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    # Getting the width and height of the video\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Writing the Overlayed Video Files Using the VideoWriter Object\n",
    "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), 24, (original_video_width, original_video_height))\n",
    "\n",
    "    while True:\n",
    "        # Reading The Frame\n",
    "        status, frame = video_reader.read()\n",
    "        \n",
    "        if not status:\n",
    "            break\n",
    "\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
    "        predicted_labels_probabilities = model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    "\n",
    "        # Appending predicted label probabilities to the deque object\n",
    "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
    "\n",
    "        # Assuring that the Deque is completely filled before starting the averaging process\n",
    "        if len(predicted_labels_probabilities_deque) == window_size:\n",
    "        \n",
    "            # Converting Predicted Labels Probabilities Deque into Numpy array\n",
    "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
    "\n",
    "            # Calculating Average of Predicted Labels Probabilities Column Wise\n",
    "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "\n",
    "            # Converting the predicted probabilities into labels by returning the index of the maximum value.\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
    "\n",
    "            # Accessing The Class Name using predicted label.\n",
    "            predicted_class_name = classes_list[predicted_label]\n",
    "\n",
    "            # Overlaying Class Name Text Ontop of the Frame\n",
    "            cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Writing The Frame\n",
    "        video_writer.write(frame)\n",
    "\n",
    "        # cv2.imshow('Predicted Frames', frame)\n",
    "        # key_pressed = cv2.waitKey(10)\n",
    "        # if key_pressed == ord('q'):\n",
    "        #     break\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    # Closing the VideoCapture and VideoWriter objects and releasing all resources held by them.\n",
    "    video_reader.release()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating The Output directories if it does not exist\n",
    "output_directory = 'Youtube_Videos'\n",
    "os.makedirs(output_directory, exist_ok = True)\n",
    "\n",
    "# Downloading a YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=8u0qjmHIOcE', output_directory)\n",
    " \n",
    "# Getting the YouTube Video's path you just downloaded\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0725a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting sthe Window Size which will be used by the Rolling Average Proces\n",
    "window_size = 1\n",
    "\n",
    "# Constructing The Output YouTube Video Path\n",
    "output_video_file_path = f'{output_directory}/{video_title} -Output-WSize {window_size}.mp4'\n",
    "\n",
    "# Calling the predict_on_live_video method to start the Prediction.\n",
    "predict_on_live_video(input_video_file_path, output_video_file_path, window_size)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(output_video_file_path).ipython_display(width = 700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b2d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Window Size which will be used by the Rolling Average Process\n",
    "window_size = 25\n",
    "\n",
    "# Constructing The Output YouTube Video Path\n",
    "output_video_file_path = f'{output_directory}/{video_title} -Output-WSize {window_size}.mp4'\n",
    "\n",
    "# Calling the predict_on_live_video method to start the Prediction and Rolling Average Process\n",
    "predict_on_live_video(input_video_file_path, output_video_file_path, window_size)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(output_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 9 [Usando método de CNN frame singular]\n",
    "\n",
    "def make_average_predictions(video_file_path, predictions_frames_count):\n",
    "    # Initializing the Numpy array which will store Prediction Probabilities\n",
    "    predicted_labels_probabilities_np = np.zeros((predictions_frames_count, model_output_size), dtype = np.float)\n",
    "\n",
    "    # Reading the Video File using the VideoCapture Object\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    # Getting The Total Frames present in the video\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Calculating The Number of Frames to skip Before reading a frame\n",
    "    skip_frames_window = video_frames_count // predictions_frames_count\n",
    "\n",
    "    for frame_counter in range(predictions_frames_count):\n",
    "\n",
    "        # Setting Frame Position\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "\n",
    "        # Reading The Frame\n",
    "        _ , frame = video_reader.read()\n",
    "\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "\n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
    "        predicted_labels_probabilities = model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    "\n",
    "        # Appending predicted label probabilities to the deque object\n",
    "        predicted_labels_probabilities_np[frame_counter] = predicted_labels_probabilities\n",
    "\n",
    "    # Calculating Average of Predicted Labels Probabilities Column Wise\n",
    "    predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "\n",
    "    # Sorting the Averaged Predicted Labels Probabilities\n",
    "    predicted_labels_probabilities_averaged_sorted_indexes = np.argsort(predicted_labels_probabilities_averaged)[::-1]\n",
    "\n",
    "    # Iterating Over All Averaged Predicted Label Probabilities\n",
    "    for predicted_label in predicted_labels_probabilities_averaged_sorted_indexes:\n",
    "\n",
    "        # Accessing The Class Name using predicted label.\n",
    "        predicted_class_name = classes_list[predicted_label]\n",
    "\n",
    "        # Accessing The Averaged Probability using predicted label.\n",
    "        predicted_probability = predicted_labels_probabilities_averaged[predicted_label]\n",
    "\n",
    "        print(f\"CLASS NAME: {predicted_class_name}   AVERAGED PROBABILITY: {(predicted_probability*100):.2}\")\n",
    "\n",
    "    # Closing the VideoCapture Object and releasing all resources held by it.\n",
    "    video_reader.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc77149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading The YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=ceRjxW4MpOY', output_directory)\n",
    "\n",
    "# Constructing The Input YouTube Video Path\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "\n",
    "# Calling The Make Average Method To Start The Process\n",
    "make_average_predictions(input_video_file_path, 50)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(input_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading The YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=ayI-e3cJM-0', output_directory)\n",
    "\n",
    "# Constructing The Input YouTube Video Path\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "\n",
    "# Calling The Make Average Method To Start The Process\n",
    "make_average_predictions(input_video_file_path, 50)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(input_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading The YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=XqqpZS0c1K0', output_directory)\n",
    "\n",
    "# Constructing The Input YouTube Video Path\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "\n",
    "# Calling The Make Average Method To Start The Process\n",
    "make_average_predictions(input_video_file_path, 50)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(input_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading The YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=WHBu6iePxKc', output_directory)\n",
    "\n",
    "# Constructing The Input YouTube Video Path\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "\n",
    "# Calling The Make Average Method To Start The Process\n",
    "make_average_predictions(input_video_file_path, 50)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(input_video_file_path).ipython_display(width = 700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
